{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x1, y1), (x2, y2) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((x1, x2), axis=0)\n",
    "y = np.concatenate((y1, y2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x1, y1, x2, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from scipy.misc import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 32\n",
    "noise_size = 2048\n",
    "batch_size = 50\n",
    "classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    \n",
    "    noise = Input(shape=(noise_size, ))\n",
    "    label = Input(shape=(1, ))\n",
    "    \n",
    "    label_embedding = Flatten()(Embedding(classes, noise_size)(label))\n",
    "    \n",
    "    model_input = multiply([noise, label_embedding])\n",
    "    \n",
    "    x = Dense(2048)(model_input)\n",
    "    \n",
    "    x = Reshape((2, 2, 512))(x)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = LeakyReLU(0.1)(x)\n",
    "    \n",
    "    x = Conv2DTranspose(256, (5, 5), padding='same', strides=2)(x)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = LeakyReLU(0.1)(x)\n",
    "    \n",
    "    x = Conv2DTranspose(128, (5, 5), padding='same', strides=2)(x)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = LeakyReLU(0.1)(x)\n",
    "    \n",
    "    x = Conv2DTranspose(64, (5, 5), padding='same', strides=2)(x)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = LeakyReLU(0.1)(x)\n",
    "    \n",
    "    x = Conv2DTranspose(3, (5, 5), padding='same', strides=2)(x)\n",
    "    img = Activation('tanh')(x)\n",
    "    \n",
    "    return Model([noise, label], img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    \n",
    "    img = Input(shape=(img_size, img_size, 3))\n",
    "    \n",
    "    x = GaussianNoise(0.1)(img)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), padding='same', strides = 2)(x)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "        \n",
    "    x = Conv2D(128, (3, 3), padding='same', strides = 2)(x)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "        \n",
    "    x = Conv2D(256, (3, 3), padding='same', strides = 2)(x)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "        \n",
    "    x = Conv2D(512, (3, 3), padding='same', strides = 2)(x)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    \n",
    "    label = Input(shape=(1, ))\n",
    "    label_embedding = Flatten()(Embedding(classes, noise_size)(label))\n",
    "    \n",
    "    flat_img = Flatten()(x)\n",
    "    \n",
    "    model_input = multiply([flat_img, label_embedding])\n",
    "\n",
    "    nn = Dropout(0.3)(model_input)\n",
    "    \n",
    "    validity = Dense(1, activation='sigmoid')(nn)\n",
    "    \n",
    "    return Model([img, label], validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = discriminator()\n",
    "d_model.compile(loss=['binary_crossentropy'], optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
    "d_model.trainable = False\n",
    "g_model = generator()\n",
    "\n",
    "noise = Input(shape=(noise_size, ))\n",
    "label = Input(shape=(1, ))\n",
    "img = g_model([noise, label])\n",
    "\n",
    "valid = d_model([img, label])\n",
    "\n",
    "combined = Model([noise, label], valid)\n",
    "combined.compile(loss=['binary_crossentropy'], optimizer=Adam(lr=0.001, beta_1=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        random = np.random.randint(0, 11)\n",
    "        \n",
    "        for index in range(int(x.shape[0]/batch_size)):\n",
    "                     \n",
    "            valid = np.ones((batch_size, 1)) - (np.random.random()*0.1)\n",
    "            fake = np.zeros((batch_size, 1)) + (np.random.random()*0.1)\n",
    "            \n",
    "            x_train = x[index*batch_size : (index+1)*batch_size]\n",
    "            y_train = y[index*batch_size : (index+1)*batch_size]\n",
    "            x_train = (x_train - 127.5)/127.5\n",
    "            \n",
    "            if index % 100 == random:\n",
    "                valid = np.zeros((batch_size, 1)) + (np.random.random()*0.1)\n",
    "                fake = np.ones((batch_size, 1)) - (np.random.random()*0.1)\n",
    "            \n",
    "            noise = np.random.randn(batch_size, noise_size)\n",
    "            gen_img = g_model.predict([noise, y_train])\n",
    "                        \n",
    "            d_loss_real = d_model.train_on_batch([x_train, y_train], valid)\n",
    "            d_loss_fake = d_model.train_on_batch([gen_img, y_train], fake)\n",
    "            d_loss = 0.5*(np.add(d_loss_real, d_loss_fake))\n",
    "\n",
    "            sample_label = np.random.randint(0, 10, batch_size).reshape(-1, 1)\n",
    "\n",
    "            valid = np.ones((batch_size, 1))\n",
    "            \n",
    "            g_loss = combined.train_on_batch([noise, sample_label], valid)\n",
    "\n",
    "            if index % (batch_size) == 0:\n",
    "                print(index)\n",
    "                print(\"%d [D loss: %f] [G loss: %f]\" % (epoch, d_loss, g_loss))\n",
    "                sample_images(epoch)\n",
    "        \n",
    "        name = './weights/combined_' + str(epoch) + '.h5'\n",
    "        combined.save_weights(name)\n",
    "        \n",
    "        time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(epoch):\n",
    "    r = 2\n",
    "    c = 5\n",
    "    noise = np.random.randn(10, noise_size)\n",
    "    sample_label = np.arange(0, 10).reshape(-1, 1)\n",
    "            \n",
    "    gen_img = g_model.predict([noise, sample_label])\n",
    "        \n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            img = image.array_to_img(gen_img[cnt])\n",
    "            axs[i,j].imshow(img)\n",
    "            axs[i,j].set_title(\"Class: %d\" % sample_label[cnt])\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(\"images/%d.png\" % epoch)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name = 'weights/combined.h5'\n",
    "#combined.load_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
